{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying pre-trained PyTorch vision models with Amazon SageMaker Neo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Neo is API to compile machine learning models to optimize them for our choice of hardward targets. Currently, Neo supports pre-trained PyTorch models from [TorchVision](https://pytorch.org/docs/stable/torchvision/models.html). General support for other PyTorch models is forthcoming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 748.9MB 42kB/s  eta 0:00:01    54% |█████████████████▎              | 405.2MB 53.6MB/s eta 0:00:07\n",
      "\u001b[?25hCollecting torchvision==0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e6/a564eba563f7ff53aa7318ff6aaa5bd8385cbda39ed55ba471e95af27d19/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 8.8MB 7.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch==1.2.0) (1.18.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision==0.4.0) (5.4.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision==0.4.0) (1.11.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "  Found existing installation: torchvision 0.5.0\n",
      "    Uninstalling torchvision-0.5.0:\n",
      "      Successfully uninstalled torchvision-0.5.0\n",
      "Successfully installed torch-1.2.0 torchvision-0.4.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!~/anaconda3/envs/pytorch_p36/bin/pip install torch==1.2.0 torchvision==0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ResNet18 from TorchVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import [ResNet18](https://arxiv.org/abs/1512.03385) model from TorchVision and create a model artifact `model.tar.gz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/ec2-user/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 104MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import tarfile\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "input_shape = [1,3,224,224]\n",
    "trace = torch.jit.trace(resnet18.float().eval(), torch.zeros(input_shape).float())\n",
    "trace.save('model.pth')\n",
    "\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as f:\n",
    "    f.add('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke Neo Compilation API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then forward the model artifact to Neo Compilation API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "compilation_job_name = name_from_base('TorchVision-ResNet18-Neo')\n",
    "\n",
    "model_key = '{}/model/model.tar.gz'.format(compilation_job_name)\n",
    "model_path = 's3://{}/{}'.format(bucket, model_key)\n",
    "boto3.resource('s3').Bucket(bucket).upload_file('model.tar.gz', model_key)\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "data_shape = '{\"input0\":[1,3,224,224]}'\n",
    "target_device = 'ml_c5'\n",
    "framework = 'PYTORCH'\n",
    "framework_version = '1.2.0'\n",
    "compiled_model_path = 's3://{}/{}/output'.format(bucket, compilation_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CompilationJobArn': 'arn:aws:sagemaker:us-east-1:111652037296:compilation-job/TorchVision-ResNet18-Neo-2020-04-17-02-20-54-739', 'ResponseMetadata': {'RequestId': '53dd7e26-2121-44b3-8a38-b4ad954cd7a1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '53dd7e26-2121-44b3-8a38-b4ad954cd7a1', 'content-type': 'application/x-amz-json-1.1', 'content-length': '129', 'date': 'Fri, 17 Apr 2020 02:20:54 GMT'}, 'RetryAttempts': 0}}\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Compiling ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "response = sm_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': model_path,\n",
    "        'DataInputConfig': data_shape,\n",
    "        'Framework': framework\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': compiled_model_path,\n",
    "        'TargetDevice': target_device\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 300\n",
    "    }\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Poll every 30 sec\n",
    "while True:\n",
    "    response = sm_client.describe_compilation_job(CompilationJobName=compilation_job_name)\n",
    "    if response['CompilationJobStatus'] == 'COMPLETED':\n",
    "        break\n",
    "    elif response['CompilationJobStatus'] == 'FAILED':\n",
    "        raise RuntimeError('Compilation failed')\n",
    "    print('Compiling ...')\n",
    "    time.sleep(30)\n",
    "print('Done!')\n",
    "\n",
    "# Extract compiled model artifact\n",
    "compiled_model_path = response['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prediction endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a prediction endpoint, we first specify two additional functions, to be used with Neo Deep Learning Runtime:\n",
    "\n",
    "* `neo_preprocess(payload, content_type)`: Function that takes in the payload and Content-Type of each incoming request and returns a NumPy array. Here, the payload is byte-encoded NumPy array, so the function simply decodes the bytes to obtain the NumPy array.\n",
    "* `neo_postprocess(result)`: Function that takes the prediction results produced by Deep Learining Runtime and returns the response body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mneo_preprocess\u001b[39;49;00m(payload, content_type):\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mPIL.Image\u001b[39;49;00m   \u001b[37m# Training container doesn't have this package\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\n",
      "\n",
      "    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInvoking user-defined pre-processing function\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m content_type != \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/x-image\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mContent type must be application/x-image\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    f = io.BytesIO(payload)\n",
      "    \u001b[37m# Load image and convert to RGB space\u001b[39;49;00m\n",
      "    image = PIL.Image.open(f).convert(\u001b[33m'\u001b[39;49;00m\u001b[33mRGB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[37m# Resize\u001b[39;49;00m\n",
      "    image = np.asarray(image.resize((\u001b[34m224\u001b[39;49;00m, \u001b[34m224\u001b[39;49;00m)))\n",
      "\n",
      "    \u001b[37m# Normalize\u001b[39;49;00m\n",
      "    mean_vec = np.array([\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m])\n",
      "    stddev_vec = np.array([\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m])\n",
      "    image = (image/\u001b[34m255\u001b[39;49;00m- mean_vec)/stddev_vec\n",
      "\n",
      "    \u001b[37m# Transpose\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(image.shape) == \u001b[34m2\u001b[39;49;00m:  \u001b[37m# for greyscale image\u001b[39;49;00m\n",
      "        image = np.expand_dims(image, axis=\u001b[34m2\u001b[39;49;00m)\n",
      "    \n",
      "    image = np.rollaxis(image, axis=\u001b[34m2\u001b[39;49;00m, start=\u001b[34m0\u001b[39;49;00m)[np.newaxis, :]\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m image\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mneo_postprocess\u001b[39;49;00m(result):\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInvoking user-defined post-processing function\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Softmax (assumes batch size 1)\u001b[39;49;00m\n",
      "    result = np.squeeze(result)\n",
      "    result_exp = np.exp(result - np.max(result))\n",
      "    result = result_exp / np.sum(result_exp)\n",
      "\n",
      "    response_body = json.dumps(result.tolist())\n",
      "    content_type = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m response_body, content_type\n"
     ]
    }
   ],
   "source": [
    "!pygmentize resnet18.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the Python script containing the two functions to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_key = '{}/source/sourcedir.tar.gz'.format(compilation_job_name)\n",
    "source_path = 's3://{}/{}'.format(bucket, source_key)\n",
    "\n",
    "with tarfile.open('sourcedir.tar.gz', 'w:gz') as f:\n",
    "    f.add('resnet18.py')\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).upload_file('sourcedir.tar.gz', source_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a SageMaker model record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelArn': 'arn:aws:sagemaker:us-east-1:111652037296:model/torchvision-resnet18-neo-2020-04-17-02-22-27-353', 'ResponseMetadata': {'RequestId': 'd823f419-8df4-444b-baa4-6a834c8eb0cc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'd823f419-8df4-444b-baa4-6a834c8eb0cc', 'content-type': 'application/x-amz-json-1.1', 'content-length': '110', 'date': 'Fri, 17 Apr 2020 02:22:27 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import NEO_IMAGE_ACCOUNT\n",
    "from sagemaker.fw_utils import create_image_uri\n",
    "\n",
    "model_name = name_from_base('TorchVision-ResNet18-Neo')\n",
    "\n",
    "image_uri = create_image_uri(region, 'neo-' + framework.lower(), target_device.replace('_', '.'),\n",
    "                             framework_version, py_version='py3', account=NEO_IMAGE_ACCOUNT[region])\n",
    "\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': image_uri,\n",
    "        'ModelDataUrl': compiled_model_path,\n",
    "        'Environment': { 'SAGEMAKER_SUBMIT_DIRECTORY': source_path }\n",
    "    },\n",
    "    ExecutionRoleArn=role\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create an Endpoint Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint-config/torchvision-resnet18-neo-2020-04-17-02-22-27-353', 'ResponseMetadata': {'RequestId': '874ef9ea-8f7b-4cf7-a00f-31cc4de38a30', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '874ef9ea-8f7b-4cf7-a00f-31cc4de38a30', 'content-type': 'application/x-amz-json-1.1', 'content-length': '129', 'date': 'Fri, 17 Apr 2020 02:22:27 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "config_name = model_name\n",
    "\n",
    "response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'default-variant-name',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.c5.xlarge',\n",
    "            'InitialVariantWeight': 1.0\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create an Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EndpointArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint/torchvision-resnet18-neo-2020-04-17-02-22-27-353-endpoint', 'ResponseMetadata': {'RequestId': '0e7df91f-1300-4458-bc9c-898bb063e288', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '0e7df91f-1300-4458-bc9c-898bb063e288', 'content-type': 'application/x-amz-json-1.1', 'content-length': '125', 'date': 'Fri, 17 Apr 2020 02:22:28 GMT'}, 'RetryAttempts': 0}}\n",
      "Creating endpoint ...\n",
      "{'EndpointName': 'TorchVision-ResNet18-Neo-2020-04-17-02-22-27-353-Endpoint', 'EndpointArn': 'arn:aws:sagemaker:us-east-1:111652037296:endpoint/torchvision-resnet18-neo-2020-04-17-02-22-27-353-endpoint', 'EndpointConfigName': 'TorchVision-ResNet18-Neo-2020-04-17-02-22-27-353', 'ProductionVariants': [{'VariantName': 'default-variant-name', 'DeployedImages': [{'SpecifiedImage': '785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-neo-pytorch:1.2.0-cpu-py3', 'ResolvedImage': '785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-neo-pytorch@sha256:c72b8031bcb83ba84b4d824f52c02783c47151529843b658e6a426dbb2015f7c', 'ResolutionTime': datetime.datetime(2020, 4, 17, 2, 22, 30, 219000, tzinfo=tzlocal())}], 'CurrentWeight': 1.0, 'DesiredWeight': 1.0, 'CurrentInstanceCount': 1, 'DesiredInstanceCount': 1}], 'EndpointStatus': 'InService', 'CreationTime': datetime.datetime(2020, 4, 17, 2, 22, 28, 353000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2020, 4, 17, 2, 28, 44, 754000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'b59a4015-6fe3-4d15-8fc0-20d0ad4ed4ec', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b59a4015-6fe3-4d15-8fc0-20d0ad4ed4ec', 'content-type': 'application/x-amz-json-1.1', 'content-length': '833', 'date': 'Fri, 17 Apr 2020 02:28:58 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = model_name + '-Endpoint'\n",
    "\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=config_name,\n",
    ")\n",
    "print(response)\n",
    "\n",
    "print('Creating endpoint ...')\n",
    "waiter = sm_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to send a cat picture.\n",
    "\n",
    "![title](cat.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '9300f2c6-954c-4625-8c87-bc2ad2ffdbae', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9300f2c6-954c-4625-8c87-bc2ad2ffdbae', 'x-amzn-invoked-production-variant': 'default-variant-name', 'date': 'Fri, 17 Apr 2020 02:28:59 GMT', 'content-type': 'application/json', 'content-length': '23362'}, 'RetryAttempts': 0}, 'ContentType': 'application/json', 'InvokedProductionVariant': 'default-variant-name', 'Body': <botocore.response.StreamingBody object at 0x7fa7a56bb278>}\n",
      "Most likely class: 282\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "sm_runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "with open('cat.jpg', 'rb') as f:\n",
    "    payload = f.read()\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                      ContentType='application/x-image',\n",
    "                                      Body=payload)\n",
    "print(response)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print('Most likely class: {}'.format(np.argmax(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: label -  'tiger cat', probability - 0.6977682113647461\n"
     ]
    }
   ],
   "source": [
    "# Load names for ImageNet classes\n",
    "object_categories = {}\n",
    "with open(\"imagenet1000_clsidx_to_labels.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        key, val = line.strip().split(':')\n",
    "        object_categories[key] = val\n",
    "print(\"Result: label - \" + object_categories[str(np.argmax(result))]+ \" probability - \" + str(np.amax(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "Having an endpoint running will incur some costs. Therefore as a clean-up job, we should delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
